<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TRAJECTORY</title>
    <link rel = "icon" class="log" href = 
    "./../../../images/icons8-open-book-emoji-48.png" 
            type = "image/x-icon">
    <link rel="stylesheet" href="../../../homestyle.css">
    <link rel="stylesheet" href="../sem7/semester7.css">
    <link rel="stylesheet" href="/main pages/academics/academicsstyle.css">
    <!-- google font(MONTSERRAT) -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800;900&display=swap"
        rel="stylesheet">

</head>

<body>
    <nav>
        <div class="container nav_container" style="margin-left: 90px;">
            <img class="log" src="./../../../images/Trajectory.svg">
            <a href="../../../index.html">
                
                <h4>TRAJECTORY</h4>
            </a>
            <ul class="nav_menu">
                <li><a href="../../../index.html">Home</a></li>
                <li><a href="../../academics.html">Academics</a></li>
                <li><a href="../../../careers/careers.html">Career Paths</a></li>
                <li><a href="../../../competitives/competitive.html">Competitive Exams</a></li>
            </ul>
            <button id="open-menu-btn">
                <?xml version="1.0" ?>
                <!DOCTYPE svg PUBLIC '-//W3C//DTD SVG 1.1//EN' 'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg
                    height="32px" id="Layer_1" style="enable-background:new 0 0 32 32;" version="1.1"
                    viewBox="0 0 32 32" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                        d="M4,10h24c1.104,0,2-0.896,2-2s-0.896-2-2-2H4C2.896,6,2,6.896,2,8S2.896,10,4,10z M28,14H4c-1.104,0-2,0.896-2,2  s0.896,2,2,2h24c1.104,0,2-0.896,2-2S29.104,14,28,14z M28,22H4c-1.104,0-2,0.896-2,2s0.896,2,2,2h24c1.104,0,2-0.896,2-2  S29.104,22,28,22z" />
                </svg>
            </button>
            <button id="close-menu-btn">
                <?xml version="1.0" ?>
                <!DOCTYPE svg PUBLIC '-//W3C//DTD SVG 1.1//EN' 'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg
                    height="512px" id="Layer_1" style="enable-background:new 0 0 512 512;" version="1.1"
                    viewBox="0 0 512 512" width="512px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"
                    xmlns:xlink="http://www.w3.org/1999/xlink">
                    <path
                        d="M443.6,387.1L312.4,255.4l131.5-130c5.4-5.4,5.4-14.2,0-19.6l-37.4-37.6c-2.6-2.6-6.1-4-9.8-4c-3.7,0-7.2,1.5-9.8,4  L256,197.8L124.9,68.3c-2.6-2.6-6.1-4-9.8-4c-3.7,0-7.2,1.5-9.8,4L68,105.9c-5.4,5.4-5.4,14.2,0,19.6l131.5,130L68.4,387.1  c-2.6,2.6-4.1,6.1-4.1,9.8c0,3.7,1.4,7.2,4.1,9.8l37.4,37.6c2.7,2.7,6.2,4.1,9.8,4.1c3.5,0,7.1-1.3,9.8-4.1L256,313.1l130.7,131.1  c2.7,2.7,6.2,4.1,9.8,4.1c3.5,0,7.1-1.3,9.8-4.1l37.4-37.6c2.6-2.6,4.1-6.1,4.1-9.8C447.7,393.2,446.2,389.7,443.6,387.1z" />
                </svg>
            </button>
        </div>
    </nav>
    <!-- ***********END OF NAVBAR *************-->
    <!-- UNITS -->
    <button class="collapsible" id="one">UNIT 1 - Introduction, Regular Expressions, Text Normalization and Edit
        Distance :</button>
    <div class="content">
        <p><a class="link" href="https://www.analyticsvidhya.com/blog/2021/06/part-13-step-by-step-guide-to-master-nlp-regular-expressions/" target="_blank">Regular
                Expressions</a>, <a class="link"
                href="https://www.scaler.com/topics/nlp/what-is-text-normalization-in-nlp/"
                target="_blank">Corpora Text Normalization</a>, <a class="link"
                href="https://www.ideserve.co.in/learn/edit-distance-dynamic-programming#:~:text=Minimum%20Edit%20distance%20between%20two,str1%20transforms%20str1%20into%20str2." target="_blank">Minimum Edit
                Distance</a>.<br><b>N-gram Language Models :</b> <a class="link"
                href="https://www.geeksforgeeks.org/n-gram-language-modelling-with-nltk/" target="_blank">N-Grams</a>, <a
                class="link" href="https://www.scaler.com/topics/nlp/language-models-in-nlp/" target="_blank">Evaluating Language
                Models</a>,
            <a class="link"
                href="https://thegradient.pub/frontiers-of-generalization-in-natural-language-processing/"
                target="_blank">Generalization and Zeros</a>, <a class="link"
                href="https://www.codingninjas.com/codestudio/library/smoothing-in-nlp"
                target="_blank">Smoothing</a>, <a class="link"
                href="https://smithamilli.com/blog/kneser-ney/"
                target="_blank">Kneser-Ney Smoothing</a>, <a class="link"
                href="https://rstudio-pubs-static.s3.amazonaws.com/253306_9828e2b22d314620b9d9f17fa6d8723e.html#/3"
                target="_blank">The Web and Stupid Backoff</a>, <a class="link"
                href="https://leimao.github.io/blog/Entropy-Perplexity/" target="_blank">Advanced: Perplexit's
                Relation to Entropy</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 2 - Logistic Regression :</button>
    <div class="content">
        <p> <a class="link" href="https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9#:~:text=Sigmoid%20is%20used%20for%20binary,extension%20of%20the%20Sigmoid%20function."
                target="_blank">
                Classification: the sigmoid</a>, <a class="link"
                href="https://www.capitalone.com/tech/machine-learning/what-is-logistic-regression/" target="_blank">Learning
                in LR</a>, <a class="link" href="https://neptune.ai/blog/cross-entropy-loss-and-its-applications-in-deep-learning"
                target="_blank">the cross-entropy loss function</a>,
            <a class="link"
                href="https://www.analyticsvidhya.com/blog/2021/03/understanding-gradient-descent-algorithm/"
                target="_blank">Gradient Descent</a>,
            <a class="link"
                href="https://www.simplilearn.com/tutorials/machine-learning-tutorial/regularization-in-machine-learning#:~:text=Regularization%20refers%20to%20techniques%20that,and%20prevent%20overfitting%20or%20underfitting."
                target="_blank">Regularization</a>,
            <a class="link"
                href="https://machinelearningmastery.com/multinomial-logistic-regression-with-python/"
                target="_blank">Multinomial logistic regression</a>,
            <a class="link"
                href="https://towardsdatascience.com/explainable-artificial-intelligence-part-2-model-interpretation-strategies-75d4afa6b739"
                target="_blank">interpreting models</a>,
            <a class="link"
                href="https://mccormickml.com/2014/03/04/gradient-descent-derivation/"
                target="_blank">Deriving the Gradient Equation</a>.<b>Vector Semantics :</b>
            <a class="link" href="https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_semantic_analysis.htm#:~:text=Lexical%20Semantics,-The%20first%20part&text=It%20includes%20words%2C%20sub%2Dwords,sentences%20and%20syntax%20of%20sentence."
                target="_blank">Lexical Semantics</a>,
            <a class="link"
                href="https://medium.com/@ram.analytics1/an-introductory-notes-on-vector-semantics-tf-idf-model-and-a-toy-implementation-9046198bf7d#:~:text=Vector%20Semantics%20defines%20semantics%20%26%20interprets,and%20philosophical%20work%20of%201950s."
                target="_blank">Vector Semantics</a>,
            <a class="link"
                href="https://towardsdatascience.com/word-vectors-and-word-meaning-90493d13af76#:~:text=WHAT%20IS%20A%20WORD%20VECTOR,frequencies%20are%20represented%20with%20numbers."
                target="_blank">Words,Vectors</a>,
            <a class="link" href="https://www.geeksforgeeks.org/cosine-similarity/"
                target="_blank">Cosine for measuring similarity</a>,
            <a class="link"
                href="https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/"
                target="_blank">TF-IDF</a>,
            <a class="link" href="https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html" target="_blank">Weighing terms in the vector</a>,
            <a class="link"
                href="https://www.capitalone.com/tech/machine-learning/understanding-tf-idf/"
                target="_blank">Applications of the tf-idf vector model</a>,
            <a class="link" href="https://www.listendata.com/2022/06/pointwise-mutual-information-pmi.html?m=1" target="_blank">PMI</a>,
            <a class="link" href="https://www.analyticsvidhya.com/blog/2021/07/word2vec-for-word-embeddings-a-beginners-guide/" target="_blank">Word2vec</a>,
            <a class="link" href="https://www.kaggle.com/code/colinmorris/visualizing-embeddings-with-t-sne" target="_blank">Visualizing Embeddings</a>,
            <a class="link" href="http://www.offconvex.org/2015/12/12/word-embeddings-1/" target="_blank">Semantic properties</a>,
            <a class="link" href="https://blogs.ischool.berkeley.edu/w231/2021/05/31/machine-learning-bias-in-word-embedding-algorithms/" target="_blank">Bias,Embeddings</a>,
            <a class="link" href="https://www.r-bloggers.com/2020/07/evaluating-vector-space-models-with-word-analogies/" target="_blank">Evaluating Vector Models</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 3 - Part-of-Speech Tagging :</button>
    <div class="content">
        <p> <a class="link" href="https://www3.diism.unisi.it/~maggini/Teaching/TEL/slides%20EN/06%20-%20NLP%20-%20PoS%20Tagging.pdf" target="_blank">English Word Classes</a>,<a class="link" href="https://www.sketchengine.eu/penn-treebank-tagset/#:~:text=English%20Penn%20Treebank%20part%2Dof%2Dspeech%20Tagset&text=Atagset%20is%20a%20list%20of,token%20in%20a%20text%20corpus." target="_blank">The Penn Treebank Part-of-Speech Tagset</a>, <a class="link" href="https://www.tutorialspoint.com/natural_language_processing/natural_language_processing_part_of_speech_tagging.htm"
                target="_blank">Part-of-Speech Tagging</a>, <a class="link" href="https://www.mygreatlearning.com/blog/pos-tagging/#:~:text=HMM%20(Hidden%20Markov%20Model)%20is,%2C%20partial%20discharges%2C%20and%20bioinformatics."
                target="_blank">HMM PoS Tagging</a>, <a class="link"
                href="https://devopedia.org/maximum-entropy-markov-model"
                target="_blank">Maximum Entropy Markov Models</a>, <a class="link"
                href="https://medium.com/@plusepsilon/the-bidirectional-language-model-1f3961d1fb27"
                target="_blank">Bidirectionality</a>, <a class="link"
                href="https://www.sketchengine.eu/blog/pos-tags/#:~:text=A%20POS%20tag%20(or%20part,text%20analysis%20tools%20and%20algorithms." target="_blank">Part-of-Speech Tagging for Other Languages</a>.<br><b>Sequence Processing with Recurrent Networks :</b> <a class="link"
                href="https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/"
                target="_blank"> Simple Recurrent Networks</a>, <a class="link"
                href="https://www.mygreatlearning.com/blog/recurrent-neural-network/" target="_blank">Applications of RNNs</a>, <a class="link"
                href="https://www.researchgate.net/figure/Illustrations-of-normal-RNN-stacked-RNN-and-bidirectional-RNN_fig7_311839720" target="_blank"> Deep Networks: Stacked and Bidirectional RNNs</a>, <a class="link"
                href="https://neptune.ai/blog/recurrent-neural-network-guide" target="_blank"> Managing Context in RNNs</a>, <a class="link"
                href="https://www.analyticsvidhya.com/blog/2022/01/tutorial-on-rnn-lstm-gru-with-implementation/" target="_blank"> LSTMs and GRUs</a>, <a class="link"
                href="https://www.freecodecamp.org/news/evolution-of-tokenization/" target="_blank">Words, Characters and Byte-Pairs</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 4 - Statistical Parsing :</button>
    <div class="content">
        <p> <a class="link" href="https://www.exploredatabase.com/2020/05/formal-definition-of-probabilistic-context-free-grammar-pcfg-with-example.html"
                target="_blank">Probabilistic Context-Free Grammars</a>, <a class="link"
                href="https://www.datasciencecentral.com/some-nlp-probabilistic-context-free-grammar-pcfg-and-cky-parsing/"
                target="_blank">Probabilistic CKY Parsing of PCFGs</a>, <a class="link"
                href="https://www.exploredatabase.com/2020/04/how-to-calculated-probabilities-for-PCFG-using-treebanks.html"
                target="_blank">
                Ways to Learn PCFG Rule Probabilities</a>,
            <a class="link"
                href="https://cs.pomona.edu/~kim/CSC181S08/lectures/Lec12/Lec12.pdf"
                target="_blank"> Problems with PCFGs</a>, <a class="link"
                href="https://youtu.be/ZzXzYvWkbn8"
                target="_blank">Improving PCFGs by Splitting Non-Terminals</a>, <a class="link"
                href="https://youtu.be/ubcsi4djGig"
                target="_blank">Probabilistic Lexicalized CFGs</a>, <a class="link"
                href="https://youtu.be/iCy9nGTYNdo"
                target="_blank">Probabilistic CCG Parsing</a>, <a class="link"
                href="https://wiki.eecs.yorku.ca/course_archive/2014-15/W/6339/_media/10e-eval-2x3.pdf" target="_blank">Evaluating Parsers</a>, <a class="link"
                href="https://www.catalyzex.com/s/Human%20Parsing" target="_blank">Human Parsing</a>.<br><b>Dependency Parsing : </b> <a class="link"
                href="https://www.analyticsvidhya.com/blog/2021/12/dependency-parsing-in-natural-language-processing-with-examples/" target="_blank">Dependency Relations</a>, <a class="link"
                href="http://www.cs.cmu.edu/~sleator/paper/node19.html" target="_blank">Dependency Formalisms</a>, <a class="link"
                href="https://aclanthology.org/W05-1714.pdf" target="_blank">Dependency Treebanks</a>, <a class="link"
                href="https://youtu.be/oLHnqGmQtI4" target="_blank">Transition-Based Dependency Parsing</a>, <a class="link"
                href="https://youtu.be/dOCRzahEL84" target="_blank">Graph-Based Dependency Parsing</a>, <a class="link"
                href="https://youtu.be/hgaeB2JloJY" target="_blank">Evaluation</a>.
        </p>
    </div>
    <button class="collapsible">UNIT 5 - Computational Semantics, Semantic Parsing, Information Extraction :</button>
    <div class="content">
        <p> <a class="link" href="https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da" target="_blank">
            Named Entity Recognition</a>, <a class="link"
                href="http://nlpprogress.com/english/relationship_extraction.html"
                target="_blank">
                Relation Extraction</a>, <a class="link"
                href="https://www.qualicen.de/natural-language-processing-timeline-extraction-with-regexes-and-spacy/#"
                target="_blank">Extracting Times</a>,
            <a class="link"
                href="https://towardsdatascience.com/natural-language-processing-event-extraction-f20d634661d3#:~:text=Extracting%20events%20from%20news%20articles&text=One%20of%20its%20common%20applications,happened%20and%20when%20it%20happened."
                target="_blank">Extracting Events and their Times</a>,
            <a class="link" href="https://aclanthology.org/2021.naacl-main.70.pdf"
                target="_blank">Template Filling</a>.
        </p>
    </div>
    <button class="collapsible" id="pp"><a href="../sem7/qb.html" target="_blank">PREVIOUS PAPERS : </a></button>
    <div class="content">
        <p></p>
    </div>

    <!-- FOOTER SECTION -->
    <footer class="footer">
        <div class="container footer_container">
            <div class="footer_1">
                <a href="../../../index.html" class="footer-logo">
                    <h4>TRAJECTORY</h4>
                </a>
                <p>
                    Chart your path to Success !
                </p>
            </div>
            <div class="footer_2">
                <h4>Permalinks</h4>
                <ul class="permalinks">
                    <li><a href="../../../index.html">Home</a></li>
                    <li><a href="../../academics.html">Academics</a></li>
                    <li><a href="../../../careers/careers.html">Career Paths</a></li>
                    <li><a href="../../../competitives/competitive.html">Competitive Exams</a></li>
                </ul>
            </div>
            <div class="footer_3">
                <h4>Contact Us</h4>
                <div>
                    <p>+9121766813</p>
                    <p>kavyachowdray699@gmail.com</p>
                    <p>+9121904246</p>
                    <p>hamidazameena786@gmail.com</p>
                    <p>+9346161312</p>
                    <p>vasavi.veguru17@gmail.com</p>
                    <p>+9381780853</p>
                    <p>priyankameejuru@gmail.com</p>
                </div>
            </div>
        </div>
    </footer>
    <script src="../../../../main pages/home.js"></script>
    <script src="../semstyle.js"></script>
</body>

</html>